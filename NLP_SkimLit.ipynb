{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "8PQ6k38MM3Sj"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "import tensorflow_text as text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xNwYYGAiG99h",
    "outputId": "03aa9871-5e87-4461-b81a-7d58242f50f5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./data\\\\train_data.csv',\n",
       " './data\\\\train_data_append_label.csv',\n",
       " './data\\\\train_data_append_sentence.csv',\n",
       " './data\\\\val_data.csv',\n",
       " './data\\\\val_data_append_sentence.csv']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glob import glob\n",
    "f = glob('./data/*.csv')\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "qk1JAElrI7yj",
    "outputId": "45f62022-3135-4aff-d565-bb11df1d60f3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e853d357af5049768f2b67db91df24d6</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>[SEP][SEP] 26 IN THE HIGH COURT OF DELHI AT NE...</td>\n",
       "      <td>ANALYSIS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6d010bb61a8a43c19e6ee9d1043ffad9</td>\n",
       "      <td>96</td>\n",
       "      <td>122</td>\n",
       "      <td>[SEP] 26 IN THE HIGH COURT OF DELHI AT NEW DEL...</td>\n",
       "      <td>ANALYSIS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37cfdb87ac654fd987d5f6ac6b8ac170</td>\n",
       "      <td>122</td>\n",
       "      <td>197</td>\n",
       "      <td>26 IN THE HIGH COURT OF DELHI AT NEW DELHI[SE...</td>\n",
       "      <td>ANALYSIS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1097d8d9896944e1a33f60f921af2695</td>\n",
       "      <td>197</td>\n",
       "      <td>231</td>\n",
       "      <td>Decided on 15th May 2017[SEP] W P CRL 1021 201...</td>\n",
       "      <td>ANALYSIS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6238617acbf342b580984fd6ee002d5f</td>\n",
       "      <td>231</td>\n",
       "      <td>550</td>\n",
       "      <td>W P CRL 1021 2013 DEPARTMENT OF CUSTOMS [SEP]...</td>\n",
       "      <td>ANALYSIS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id  start  end  \\\n",
       "0  e853d357af5049768f2b67db91df24d6      0   52   \n",
       "1  6d010bb61a8a43c19e6ee9d1043ffad9     96  122   \n",
       "2  37cfdb87ac654fd987d5f6ac6b8ac170    122  197   \n",
       "3  1097d8d9896944e1a33f60f921af2695    197  231   \n",
       "4  6238617acbf342b580984fd6ee002d5f    231  550   \n",
       "\n",
       "                                                text     label  \n",
       "0  [SEP][SEP] 26 IN THE HIGH COURT OF DELHI AT NE...  ANALYSIS  \n",
       "1  [SEP] 26 IN THE HIGH COURT OF DELHI AT NEW DEL...  ANALYSIS  \n",
       "2   26 IN THE HIGH COURT OF DELHI AT NEW DELHI[SE...  ANALYSIS  \n",
       "3  Decided on 15th May 2017[SEP] W P CRL 1021 201...  ANALYSIS  \n",
       "4   W P CRL 1021 2013 DEPARTMENT OF CUSTOMS [SEP]...  ANALYSIS  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(f[2])\n",
    "test_df = pd.read_csv(f[4])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "P7DgcNOkHimV"
   },
   "outputs": [],
   "source": [
    "train_df = df.sample(frac = 0.8)\n",
    "val_df = df.drop(train_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "TgHPnhFiLP9a"
   },
   "outputs": [],
   "source": [
    "train_sentences = train_df[\"text\"].tolist()\n",
    "test_sentences = test_df[\"text\"].tolist()\n",
    "val_sentences = val_df[\"text\"].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-wbk-KmcrTsL"
   },
   "source": [
    "LABEL PREPROCESSING, CHANGING IT TO ONE HOT ENCODED ARRAY OR LABEL ENCODED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Z6J-hRyaMNRI"
   },
   "outputs": [],
   "source": [
    "# labels to numbers\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "one_hot_encoder = OneHotEncoder(sparse=False)\n",
    "train_labels_onehot = one_hot_encoder.fit_transform(train_df[\"label\"].to_numpy().reshape(-1,1))\n",
    "val_labels_onehot = one_hot_encoder.transform(val_df[\"label\"].to_numpy().reshape(-1,1))\n",
    "test_labels_onehot = one_hot_encoder.transform(test_df[\"label\"].to_numpy().reshape(-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XtHAHw-fNU15"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5ZjWDohNM8hN",
    "outputId": "b7f230c0-c4ac-4f53-c711-de4e9b1a5572"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ANALYSIS', 'ARG_PETITIONER', 'ARG_RESPONDENT', 'FAC', 'ISSUE',\n",
       "       'NONE', 'PREAMBLE', 'PRE_NOT_RELIED', 'PRE_RELIED', 'RATIO', 'RLC',\n",
       "       'RPC', 'STA'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels_encoded = label_encoder.fit_transform(train_df[\"label\"].to_numpy())\n",
    "val_labels_encoded = label_encoder.transform(val_df[\"label\"].to_numpy())\n",
    "test_labels_encoded = label_encoder.transform(test_df[\"label\"].to_numpy())\n",
    "\n",
    "classes = label_encoder.classes_\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PieZrgeJNocv",
    "outputId": "cc99cdce-6d59-4556-e726-36e9fb3f0ae9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84.2938237965486"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#average length of a sentences\n",
    "np.mean([len(sentence.split())for sentence in train_sentences])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 266
    },
    "id": "xYeg1yYiOnYK",
    "outputId": "c0c9feb0-8547-46ec-ffac-913ec57a6bdf"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.hist([len(sentence.split())for sentence in train_sentences], bins=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WPYWa8rqV4nv",
    "outputId": "7131ad0a-1621-422c-ecbf-0f12e62af5ba"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "172.34999999999854"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Top 95 percentile sentence of length is 55 words long\n",
    "np.percentile([len(sentence.split())for sentence in train_sentences],95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "65Ug5V9KWCJJ"
   },
   "outputs": [],
   "source": [
    "#TOKEN VECTORIZATION\n",
    "max_tokens = 68000\n",
    "output_seq_len =55\n",
    "text_vectorizer = TextVectorization(max_tokens=max_tokens,\n",
    "                                    output_sequence_length = output_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "8OIbjUx5W8lP"
   },
   "outputs": [],
   "source": [
    "text_vectorizer.adapt(train_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "TA3dZU0PXLUr",
    "outputId": "31efc3ee-1bb8-413e-f0eb-3e2cc7bbdb29"
   },
   "outputs": [],
   "source": [
    "#TOKEN EMBEDDING\n",
    "token_embed = layers.Embedding(input_dim=len(text_vectorizer.get_vocabulary()),\n",
    "                               output_dim=128,\n",
    "                               mask_zero =True,\n",
    "                               name =\"token_embedding\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EwzwAZVZrJMU"
   },
   "source": [
    "Characters pre-preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "K9FBcYOkaLYK"
   },
   "outputs": [],
   "source": [
    "#creating character level splits\n",
    "def split_chars(text):\n",
    "  return \" \".join(list(text))\n",
    "train_chars = [split_chars(sentence) for sentence in train_sentences]\n",
    "val_chars = [split_chars(sentence) for sentence in val_sentences]\n",
    "test_chars = [split_chars(sentence) for sentence in test_sentences]\n",
    "mean_chars_len=149\n",
    "output_seq_char_len = 290"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "bO8RrXgtde0r"
   },
   "outputs": [],
   "source": [
    "import string\n",
    "alphabet = string.ascii_lowercase+ string.digits+string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "sY9iHnnSeP9w"
   },
   "outputs": [],
   "source": [
    "## CHARACTER VECTORIZATION\n",
    "NUM_CHAR_TOKENS = len(alphabet) + 2 \n",
    "char_vectorizer = TextVectorization(max_tokens=NUM_CHAR_TOKENS,  \n",
    "                                    output_sequence_length=output_seq_char_len,\n",
    "                                    standardize=\"lower_and_strip_punctuation\",\n",
    "                                    name=\"char_vectorizer\")\n",
    "\n",
    "\n",
    "char_vectorizer.adapt(train_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "vuA7HYKrgWqM"
   },
   "outputs": [],
   "source": [
    "#CHARACTER EMBEDDING\n",
    "char_embed = layers.Embedding(input_dim = len(char_vectorizer.get_vocabulary()),\n",
    "                              output_dim= 25,\n",
    "                              mask_zero = True,\n",
    "                              name = \"char_embed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "jynIR0kVkmd3"
   },
   "outputs": [],
   "source": [
    "bert_url = 'https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3'\n",
    "bert_preprocess = 'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "NFP19A3YluNo"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"bert_preprocess_model = hub.KerasLayer(bert_preprocess,trainable=False,name='bert_preprocessor')\\nbert_model = hub.KerasLayer(bert_url,trainable=True,name='bert_encoder')\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow_hub as hub\n",
    "\"\"\"bert_preprocess_model = hub.KerasLayer(bert_preprocess,trainable=False,name='bert_preprocessor')\n",
    "bert_model = hub.KerasLayer(bert_url,trainable=True,name='bert_encoder')\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "M-ZWSKv9oMAp",
    "outputId": "5d90f1e1-f260-44da-8ca7-0e9424676200"
   },
   "outputs": [],
   "source": [
    "## create an embedding layer from tensorflow hub\n",
    "\n",
    "tf_hub_embedding_layer = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\",\n",
    "                                        trainable=True,\n",
    "                                        name=\"universal_sentence_encoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "aV1snOrMuP9P",
    "outputId": "2c26d826-75b5-466e-e5d8-fda7af847639"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'train_line_numbers_onehot = tf.one_hot(train_df[\"line_number\"].to_numpy(), depth = 15)\\nval_line_numbers_onehot = tf.one_hot(val_df[\"line_number\"].to_numpy(), depth = 15)\\ntest_line_numbers_onehot = tf.one_hot(test_df[\"line_number\"].to_numpy(), depth = 15)'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one hot encode the line number, since most of them are 15 lines long, we will go with 15\n",
    "\"\"\"train_line_numbers_onehot = tf.one_hot(train_df[\"line_number\"].to_numpy(), depth = 15)\n",
    "val_line_numbers_onehot = tf.one_hot(val_df[\"line_number\"].to_numpy(), depth = 15)\n",
    "test_line_numbers_onehot = tf.one_hot(test_df[\"line_number\"].to_numpy(), depth = 15)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "EBmLqCNBucSG",
    "outputId": "3a925dbf-5af3-4ed7-da63-90a0898e76f4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'train_total_lines_onehot = tf.one_hot(train_df[\"total_lines\"].to_numpy(), depth = 20)\\nval_total_lines_onehot = tf.one_hot(val_df[\"total_lines\"].to_numpy(), depth = 20)\\ntest_total_lines_onehot = tf.one_hot(test_df[\"total_lines\"].to_numpy(), depth = 20)'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#same idea but for total_lines\n",
    "\"\"\"train_total_lines_onehot = tf.one_hot(train_df[\"total_lines\"].to_numpy(), depth = 20)\n",
    "val_total_lines_onehot = tf.one_hot(val_df[\"total_lines\"].to_numpy(), depth = 20)\n",
    "test_total_lines_onehot = tf.one_hot(test_df[\"total_lines\"].to_numpy(), depth = 20)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "zlYWYQm0i3hn",
    "outputId": "faae86aa-db8c-414d-fd74-6c819def47c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'output_layer = layers.Dense(len(classes),activation=\\'softmax\\',name=\\'output_layer\\')(token_embeddings[\\'pooled_output\\'])\\n\\nmodel = tf.keras.Model(inputs = token_inputs,\\n                       outputs = output_layer,\\n                       name=\"model\")\\n'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## after creating character and words embeddings, time to build multi-modal model (hybrid embedding model)\n",
    "\n",
    "# 1-token (words) inputs\n",
    "token_inputs = layers.Input(shape =[], #hub layer\n",
    "                            dtype= tf.string, name =\"input\")\n",
    "\n",
    "#token_preprocess = bert_preprocess_model(token_inputs)\n",
    "#token_embeddings = bert_model(token_preprocess)\n",
    "token_embeddings = tf_hub_embedding_layer(token_inputs)\n",
    "token_output= layers.Dense(128, activation=\"relu\")(token_embeddings)#token_embeddings['pooled_output'])\n",
    "token_model = tf.keras.Model(inputs=token_inputs,outputs=token_output)\n",
    "\n",
    "# 2-char inputs\n",
    "char_inputs = layers.Input(shape=(1,), dtype=tf.string, name=\"char_input\")\n",
    "char_vectors = char_vectorizer(char_inputs)\n",
    "char_embeddings = char_embed(char_vectors)\n",
    "char_bi_lstm = layers.Bidirectional(layers.LSTM(24))(char_embeddings) \n",
    "char_model = tf.keras.Model(inputs=char_inputs,outputs=char_bi_lstm)\n",
    "\n",
    "## 3-concatenate 1, 2\n",
    "token_char_concat = layers.Concatenate(name=\"token_char_hybrid\")([token_model.output, \n",
    "                                                                  char_model.output])\n",
    "token_char_concat_output = layers.Dense(256, activation=\"relu\")(token_char_concat)\n",
    "token_char_concat_output = layers.Dropout(0.5)(token_char_concat)\n",
    "\n",
    "### 4-create model for line_number\n",
    "#line_number_input = layers.Input(shape=(15,), dtype=tf.float32, name=\"line_number_input\")\n",
    "#line_number_output = layers.Dense(32,activation=\"relu\")(line_number_input)\n",
    "#line_number_model = tf.keras.Model(inputs=line_number_input,\n",
    "                                   #outputs=line_number_output)\n",
    "## 5-create model for total lines\n",
    "#total_lines_input = layers.Input(shape=(20,), dtype=tf.float32, name=\"total_lines_input\")\n",
    "#total_lines_output = layers.Dense(32,activation=\"relu\")(total_lines_input)\n",
    "#total_lines_model = tf.keras.Model(inputs=total_lines_input,\n",
    "                                   #outputs=total_lines_output)\n",
    "\n",
    "## 6-concatenate 3,4,5\n",
    "#char_token_lines_concat = layers.Concatenate(name=\"char_token_lines_concat\")([line_number_model.output, \n",
    "                                                                              #total_lines_model.output,\n",
    "                                                                              #token_char_concat_output #didnt use .output because its not a model\n",
    "                                                                              #])\n",
    "\n",
    "\n",
    "## 7-create the output layers\n",
    "output_layer = layers.Dense(len(classes), activation =\"softmax\", name=\"output_layer\")(token_char_concat_output)\n",
    "\n",
    "model = tf.keras.Model(inputs =[token_model.input, char_model.input],\n",
    "                       outputs = output_layer,\n",
    "                       name=\"model\")\n",
    "\"\"\"output_layer = layers.Dense(len(classes),activation='softmax',name='output_layer')(token_embeddings['pooled_output'])\n",
    "\n",
    "model = tf.keras.Model(inputs = token_inputs,\n",
    "                       outputs = output_layer,\n",
    "                       name=\"model\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "doCG_AvVmsSO",
    "outputId": "d6a0ac62-288f-4e52-ff10-c6d6f4ed47e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " char_input (InputLayer)        [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " input (InputLayer)             [(None,)]            0           []                               \n",
      "                                                                                                  \n",
      " char_vectorizer (TextVectoriza  (None, 290)         0           ['char_input[0][0]']             \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " universal_sentence_encoder (Ke  (None, 512)         256797824   ['input[0][0]']                  \n",
      " rasLayer)                                                                                        \n",
      "                                                                                                  \n",
      " char_embed (Embedding)         (None, 290, 25)      1750        ['char_vectorizer[0][0]']        \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 128)          65664       ['universal_sentence_encoder[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " bidirectional (Bidirectional)  (None, 48)           9600        ['char_embed[0][0]']             \n",
      "                                                                                                  \n",
      " token_char_hybrid (Concatenate  (None, 176)         0           ['dense[0][0]',                  \n",
      " )                                                                'bidirectional[0][0]']          \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 176)          0           ['token_char_hybrid[0][0]']      \n",
      "                                                                                                  \n",
      " output_layer (Dense)           (None, 13)           2301        ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 256,877,139\n",
      "Trainable params: 256,877,139\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 223
    },
    "id": "4j0JYE8Gnn4u",
    "outputId": "7610eaab-b6c6-4ca5-ea1c-62967afc4a30"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    }
   ],
   "source": [
    "## plot the model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "plot_model(model , show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "sB2n6ekKn9Oo"
   },
   "outputs": [],
   "source": [
    "model.compile(loss =tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.2),\n",
    "              optimizer=\"adam\",\n",
    "              metrics =[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "TlVa4HmVpxpQ"
   },
   "outputs": [],
   "source": [
    "# combine chars, tokens, and numbers as an input \n",
    "train_pos_char_token_data = tf.data.Dataset.from_tensor_slices((train_sentences, train_chars)) # train_tokens,train chars\n",
    "train_pos_char_token_labels = tf.data.Dataset.from_tensor_slices(train_labels_onehot) # train labels\n",
    "train_pos_char_token_dataset = tf.data.Dataset.zip((train_pos_char_token_data, train_pos_char_token_labels)) # combine data and labels\n",
    "train_pos_char_token_dataset = train_pos_char_token_dataset.batch(8).prefetch(tf.data.AUTOTUNE) # turn into batches and prefetch appropriately\n",
    "\n",
    "# Validation dataset\n",
    "val_pos_char_token_data = tf.data.Dataset.from_tensor_slices((val_sentences,\n",
    "                                                              val_chars))\n",
    "val_pos_char_token_labels = tf.data.Dataset.from_tensor_slices(val_labels_onehot)\n",
    "val_pos_char_token_dataset = tf.data.Dataset.zip((val_pos_char_token_data, val_pos_char_token_labels))\n",
    "val_pos_char_token_dataset = val_pos_char_token_dataset.batch(8).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L6TGuMSh00zW",
    "outputId": "71f750d7-82d2-476b-caed-0178612e55d9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15414"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CaiQiSM21xf0",
    "outputId": "0b9b2244-e3db-407c-d0df-2d7cdf40349e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(len(val_pos_char_token_dataset)*0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IkulgGacqjGL",
    "outputId": "a254e7b5-97ee-4d5c-9fc8-e12b2ffec43d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "   8/1927 [..............................] - ETA: 1:27:53 - loss: 2.5370 - accuracy: 0.2188"
     ]
    }
   ],
   "source": [
    "model_history = model.fit(train_pos_char_token_dataset,\n",
    "                              #steps_per_epoch=int(0.1 * len(train_pos_char_token_dataset)),\n",
    "                              epochs=15,\n",
    "                              validation_data=val_pos_char_token_dataset)\n",
    "                              #validation_steps=int(0.1 * len(val_pos_char_token_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "USDEkJ1ucZsy"
   },
   "outputs": [],
   "source": [
    "test_pos_char_token_data = tf.data.Dataset.from_tensor_slices((test_sentences,test_chars))\n",
    "test_pos_char_token_labels = tf.data.Dataset.from_tensor_slices(test_labels_onehot)\n",
    "test_pos_char_token_dataset = tf.data.Dataset.zip((test_pos_char_token_data, test_pos_char_token_labels))\n",
    "test_pos_char_token_dataset = test_pos_char_token_dataset.batch(32).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1Kaf3NNErt96"
   },
   "outputs": [],
   "source": [
    "model_pred_probs = model.predict(test_pos_char_token_dataset)\n",
    "model_preds = tf.argmax(model_pred_probs, axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yyOCIURpr_Gg",
    "outputId": "af06652b-5f71-4d3a-92a1-7ec3334b9691"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,precision_recall_fscore_support,classification_report\n",
    "print(classification_report(y_true= test_labels_encoded, y_pred=model_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4Dgto7-bsLy_"
   },
   "outputs": [],
   "source": [
    "def calculate_results(y_true, y_pred):\n",
    "\t\"\"\"\"\n",
    "\tEVALUATE ACCURACY, PRECISION, RECALL, F1 SCORE\n",
    "\t\"\"\"\n",
    "\tmodel_accuracy = accuracy_score(y_true, y_pred) * 100\n",
    "\tmodel_precision, model_recall, model_f1,_ = precision_recall_fscore_support(y_true, y_pred,average=\"weighted\")\n",
    "\tmodel_results = {\"accuracy\":model_accuracy,\n",
    "\t\t\t\t\t \"precision\":model_precision,\n",
    "\t\t\t\t\t \"recall\" :model_recall, \n",
    "\t\t\t\t\t \"f1\":model_f1}\n",
    "\treturn model_results\n",
    "calculate_results(y_true= test_labels_encoded, #label array outputted from the label encoder of sklearn\n",
    "                  y_pred=model_preds)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "NLP-SkimLit.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
